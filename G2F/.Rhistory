group_files[[i]]$id,group_files[[i]]$name,
subset(group_assignments,`Pre-assign Room Name` == group_files[[i]]$name)$Name[chair_position]
))),sep='\n')
cat(sapply(1:length(group_files),function(i) sprintf('<p><a href="https://docs.google.com/document/d/%s/edit">%s</a>---%s</p>',
group_files[[i]]$id,group_files[[i]]$name,
subset(group_assignments,`Pre-assign Room Name` == group_files[[i]]$name)$Name[chair_position]
)),sep='\n')
library(googledrive)
library(tidyverse)
chair_position = 1
folder = 'Lecture_01'
base_path = 'BIT 150/2020'
file='/Users/Dan/Box\ Sync/Classes/BIT150/2020/Module_01_Welcome/Lecture_1/Activity_worksheet_1.docx'
group_assignments = read_csv(file = list.files(pattern = 'Group_assignments')[1])
drive_mkdir(name=folder,path=base_path,overwrite = T)
a=drive_upload(file,path = file.path(base_path,folder),name='Assignment',overwrite = T)
group_files = list()
group = 'Room_01'
for(group in unique(group_assignments$`Pre-assign Room Name`)) {
group_files[[group]] = drive_cp(a$name,path = file.path(base_path,folder),name = group,overwrite=TRUE) %>% drive_share(role='writer',type='anyone')# %>% drive_link()
}
cat(sapply(1:length(group_files),function(i) sprintf('<p><a href="https://docs.google.com/document/d/%s/edit">%s</a>---%s</p>',
group_files[[i]]$id,group_files[[i]]$name,
subset(group_assignments,`Pre-assign Room Name` == group_files[[i]]$name)$Name[chair_position]
)),sep='\n')
library(tidyverse)
seed = sample(1:1e5,1)
set.seed(seed)
roster = read_csv('Roster.csv')
roster$Name = sapply(roster$Student,function(x) paste(trimws(strsplit(x,',',fixed=T)[[1]][2:1]),collapse=' '))
roster = roster[sample(1:nrow(roster)),]
roster$Group = sprintf('Room_%02d',rep(1:8,4)[1:nrow(roster)])
roster = bind_rows(roster,tibble(`SIS Login ID` = c('katiel4','lukeli'),Group = c('Room_01','Room_02')))
zoom_table = tibble(`Pre-assign Room Name` = roster$Group,`Email Address` = sprintf('%s@ucdavis.edu',roster$`SIS Login ID`), Name = roster$Name)
write.csv(zoom_table,file = sprintf('Group_assignments_%d.csv',seed),row.names=F)
library(googledrive)
library(tidyverse)
chair_position = 1
folder = 'Lecture_02'
base_path = 'BIT 150/2020'
file='/Users/Dan/Box\ Sync/Classes/BIT150/2020/Module_01_Welcome/Lecture_1/Activity_worksheet_1.docx /Users/Dan/Box\ Sync/Classes/BIT150/2020/Module_02_Databases/Lecture_2_primary/Assignment.docx'
group_assignments = read_csv(file = list.files(pattern = 'Group_assignments')[1])
drive_mkdir(name=folder,path=base_path,overwrite = T)
a=drive_upload(file,path = file.path(base_path,folder),name='Assignment',overwrite = T)
group_files = list()
group = 'Room_01'
for(group in unique(group_assignments$`Pre-assign Room Name`)) {
group_files[[group]] = drive_cp(a$name,path = file.path(base_path,folder),name = group,overwrite=TRUE) %>% drive_share(role='writer',type='anyone')# %>% drive_link()
}
file='/Users/Dan/Box\ Sync/Classes/BIT150/2020/Module_02_Databases/Lecture_2_primary/Assignment.docx'
group_assignments = read_csv(file = list.files(pattern = 'Group_assignments')[1])
drive_mkdir(name=folder,path=base_path,overwrite = T)
a=drive_upload(file,path = file.path(base_path,folder),name='Assignment',overwrite = T)
group_files = list()
group = 'Room_01'
for(group in unique(group_assignments$`Pre-assign Room Name`)) {
group_files[[group]] = drive_cp(a$name,path = file.path(base_path,folder),name = group,overwrite=TRUE) %>% drive_share(role='writer',type='anyone')# %>% drive_link()
}
cat(sapply(1:length(group_files),function(i) sprintf('<p><a href="https://docs.google.com/document/d/%s/edit">%s</a>---%s</p>',
group_files[[i]]$id,group_files[[i]]$name,
subset(group_assignments,`Pre-assign Room Name` == group_files[[i]]$name)$Name[chair_position]
)),sep='\n')
drive_cp(a$name,path = file.path(base_path,folder),name = group,overwrite=TRUE)
a$name
file.path(base_path,folder)
group
a$name
a
group_files[[group]] = drive_cp(a$id,path = file.path(base_path,folder),name = group,overwrite=TRUE) %>% drive_share(role='writer',type='anyone')# %>% drive_link()
group_files[[group]] = drive_cp(as_id(a$id),path = file.path(base_path,folder),name = group,overwrite=TRUE) %>% drive_share(role='writer',type='anyone')# %>% drive_link()
for(group in unique(group_assignments$`Pre-assign Room Name`)) {
group_files[[group]] = drive_cp(as_id(a$id),path = file.path(base_path,folder),name = group,overwrite=TRUE) %>% drive_share(role='writer',type='anyone')# %>% drive_link()
}
cat(sapply(1:length(group_files),function(i) sprintf('<p><a href="https://docs.google.com/document/d/%s/edit">%s</a>---%s</p>',
group_files[[i]]$id,group_files[[i]]$name,
subset(group_assignments,`Pre-assign Room Name` == group_files[[i]]$name)$Name[chair_position]
)),sep='\n')
library(googledrive)
library(tidyverse)
chair_position = 2
folder = 'Lecture_03'
base_path = 'BIT 150/2020'
file='/Users/Dan/Box\ Sync/Classes/BIT150/2020/Module_02_Databases/Lecture_3_presentations/Presentation\ assignment.docx'
group_assignments = read_csv(file = list.files(pattern = 'Group_assignments')[1])
drive_mkdir(name=folder,path=base_path,overwrite = T)
a=drive_upload(file,path = file.path(base_path,folder),name='Assignment',overwrite = T)
group_files = list()
group = 'Room_01'
for(group in unique(group_assignments$`Pre-assign Room Name`)) {
group_files[[group]] = drive_cp(as_id(a$id),path = file.path(base_path,folder),name = group,overwrite=TRUE) %>% drive_share(role='writer',type='anyone')# %>% drive_link()
}
cat(sapply(1:length(group_files),function(i) sprintf('<p><a href="https://docs.google.com/document/d/%s/edit">%s</a>---%s</p>',
group_files[[i]]$id,group_files[[i]]$name,
subset(group_assignments,`Pre-assign Room Name` == group_files[[i]]$name)$Name[chair_position]
)),sep='\n')
setwd('~/Box Sync/DER_projects/MegaLMM_papers/GP_paper/Analyses/G2F/')
library(foreach)
library(doParallel)
library(ggplot2)
library(mapdata)
library(data.table)
library(usmap)
library(cowplot)
library(ggthemes)
library(dplyr)
library(tidyr)
source('my_pylo2map.R')
library(lme4)
library(lme4qtl)
library(geosphere)
registerDoParallel(RcppParallel::defaultNumThreads()-1)
files = list.files(path='BLUP_matrices/',pattern = 'csv')
traits = sub('_BLUPs.csv','',files,fixed=T)
traits = gsub(' ','_',traits)
traits = traits[c(4,1,2,3)]
trait_names = traits
traits = c('DTS','ASI','Grain Yield','Plant Height')
names(trait_names) = traits
a=foreach(trait. = trait_names) %do% {
print(trait.)
print(dim(fread(sprintf('BLUP_matrices/%s_BLUPs.csv',gsub('_',' ',trait.)))))
}
trait. = traits[1]
results = foreach(trait. = traits,.combine = 'bind_rows') %dopar% {
trait_name = trait_names[trait.]
foreach(i=1:20,.combine = 'bind_rows',.errorhandling = 'pass') %do% {
try({
res_BSFG = readRDS(sprintf('G2F_byTrait_results/%s_%d.rds',trait_name,i))
res_alt = readRDS(sprintf('G2F_byTrait_results/alternatives_%s_%d.rds',trait_name,i))
res_mean = readRDS(sprintf('G2F_byTrait_results/mean_%s_%d.rds',trait_name,i))
Y = res_BSFG$Y
mask = res_BSFG$mask
Y[!mask] = NA
BSFG_Eta = sapply(1:ncol(Y),function(i) cor(Y[,i],res_BSFG$Eta_m[,i],use='p'))
BSFG_U = sapply(1:ncol(Y),function(i) cor(Y[,i],res_BSFG$U[,i],use='p'))
rrBLUP = sapply(1:ncol(Y),function(i) cor(Y[,i],res_alt$U_rrBLUP[,i],use='p'))
phenix_Y = sapply(1:ncol(Y),function(i) cor(Y[,i],res_alt$Y_phenix[,i],use='p'))
phenix_U = sapply(1:ncol(Y),function(i) cor(Y[,i],res_alt$U_phenix[,i],use='p'))
means_U = sapply(1:ncol(Y),function(i) cor(Y[,i],res_mean$U[,i],use='p'))
results = data.frame(trait=trait.,i=i,SiteYear = colnames(Y),BSFG_Eta,BSFG_U,rrBLUP,phenix_Y,phenix_U,means_U)
})
}
}
summ = aggregate(cbind(BSFG_Eta,BSFG_U,rrBLUP,phenix_Y,phenix_U,means_U)~trait,results,FUN=mean)
summ
results_subset = results[,c('trait','i','SiteYear','BSFG_Eta','phenix_Y','means_U','rrBLUP')]
colnames(results_subset)[4:7] = c('MegaLMM','phenix','GBLUP(env BLUPs)','GBLUP(univariate)')
library(emmeans)
summ_results = foreach(trait. = traits,.combine = 'rbind') %do% {
results_trait = subset(results_subset,trait == trait.)
# results_trait_means = aggregate(cbind(BSFG_Eta,BSFG_U,rrBLUP,phenix_Y,phenix_U,means_U)~SiteYear+trait,results_trait,FUN=mean)
results_trait_means = aggregate(cbind(MegaLMM,phenix,`GBLUP(env BLUPs)`,`GBLUP(univariate)`)~SiteYear+trait,results_trait,FUN=mean)
results_trait_means_tall = pivot_longer(results_trait_means,cols = -c(1:2))
res = lm(value ~ SiteYear + name,results_trait_means_tall)
effects = summary(emmeans(res,spec = 'name'))
data.frame(Trait = trait.,as.data.frame(effects))
}
position = position_dodge()
summ_results$name = factor(summ_results$name,levels = unique(summ_results$name)[c(2,1,4,3)])
(p_accuracy <- ggplot(summ_results,aes(x=Trait,y=emmean)) +
geom_errorbar(aes(group = interaction(name,Trait),ymin = lower.CL,ymax = upper.CL),position=position_dodge(),size=.5) +
geom_bar(aes(group = interaction(name,Trait),fill = name),stat='identity',position = position_dodge()) +
scale_fill_discrete(name = 'Method') +
ylab('Estimated prediction accuracy')
)
fields_metadata = fread('Data/fields_locations_allYears.csv',data.table=F)
fields_metadata$SiteYear = gsub('-','.',fields_metadata$SiteYear)
fields_metadata$Year = sapply(fields_metadata$SiteYear,function(x) {a=strsplit(x,'.',fixed=T)[[1]];a[length(a)]})
fields_metadata$location = paste(fields_metadata$Experiment,fields_metadata$City)
fields_metadata$location[fields_metadata$location == 'ARH1 Mariana'] = 'ARH1 Marianna'
site_distance = distm(fields_metadata[,c('long','lat')])
rownames(site_distance) = colnames(site_distance) = fields_metadata$SiteYear
head(fields_metadata)
fields_2014 = fread('Data/g2f_2014_field_characteristics.csv',data.table=F)
head(fields_2014)
fields_2014
head(fields_2014)
colnames(fields_2014)
fields_2015 = fread('Data/g2f_2015_field_metadata.csv',data.table=F)
fields_2016 = fread('Data/g2f_2016_field_metadata.csv',data.table=F)
fields_2017 = fread('Data/g2f_2017_field_metadata.csv',data.table=F)
colnames(fields_2015)
colnames(fields_2016)
colnames(fields_2017)
fields_2016$Pounds_Needed_Soil_Moisture
fields_2015$Pounds_Needed_Soil_Moisture
fields_2017$Pounds_Needed_Soil_Moisture
# Lambdas
library(MegaLMM)
trait. = traits[4]
traits
trait. = traits[1]
Lambda = readRDS(sprintf('G2F_byTrait_Gcors/Lambda_%s_1.rds',trait.))
fields_metadata_trait = fields_metadata[match(rownames(Lambda),fields_metadata$SiteYear),]
Lambda = sweep(Lambda,2,sign(colMeans(Lambda)),'*')
Lambda = readRDS('G2F_byTrait_Gcors/Lambda_Silk_DAP_1.rds')
dim(Lambda)
Image(Lambda)
Lambdas = lapply(list.files(pattern = 'Lambda',path = 'G2F_byTrait_Gcors/'),readRDS)
Lambdas = lapply(list.files(pattern = 'Lambda',path = 'G2F_byTrait_Gcors/',full.names = T),readRDS)
Image(Lambdas[[1]])
Image(Lambdas[[2]])
Image(Lambdas[[3]])
Image(Lambdas[[4]])
Image(cor(Lambdas[[1]],Lambdas[[2]]))
rownames(Lambdas[[1]])
rownames(Lambdas[[2]])
options(error=NULL)
?union
i = intersect(rownames(Lambdas[[1]]),rownames(Lambdas[[2]]))
Image(cor(Lambdas[[1]][i,],Lambdas[[2]][i,]))
i = intersect(rownames(Lambdas[[1]]),rownames(Lambdas[[3]]))
Image(cor(Lambdas[[1]][i,],Lambdas[[3]][i,]))
i = intersect(rownames(Lambdas[[1]]),rownames(Lambdas[[4]]))
Image(cor(Lambdas[[1]][i,],Lambdas[[4]][i,]))
Image(Lambdas[[1]][,-1])
Image(Lambdas[[2]][,-1])
Image(Lambdas[[3]][,-1])
Image(Lambdas[[4]][,-1])
boxplot(abs(Lambdas[[1]]))
boxplot(abs(Lambdas[[2]]))
boxplot(abs(Lambdas[[3]]))
boxplot(abs(Lambdas[[4]]))
Gs = readRDS('G2F_byTrait_Gcors/Gcor_Silk_DAP_1.rds')
Ys = fread('BLUP_matrices/Silk DAP_BLUPs.csv',data.table=F)
colnames(Ys) == colnames(Gs)
dim(Ys)
dim(Gs)
Ys[1:10,1:10]
Ys = fread('BLUP_matrices/Silk DAP_BLUPs.csv',data.table=F);rownames(Ys) = Ys[,1];Ys = Ys[,-1]
colnames(Ys) == colnames(Gs)
colnames(Ys) %in% colnames(Gs)
colnames(Ys)
colnames(Gs)
sub('-','.',colnames(Ys),fixed=T) == colnames(Gs)
plot(cor(Ys,use='p'),Gs)
x = upper.tri(cor(Ys,use='p'))
plot(cor(Ys,use='p')[x],Gs[x])
abline(0,1)
plot(cor(Ys,use='p')[x],crossprod(Lambdas[[4]])[x])
plot(cor(Ys,use='p')[x],tcrossprod(Lambdas[[4]])[x])
plot(cov(Ys,use='p')[x],tcrossprod(Lambdas[[4]])[x])
abline(0,1)
dim(tcrossprod(Lambdas[[4]]))
rownames(Lambdas[[4]])
Image(tcrossprod(Lambdas[[4]]))
Image(Gs)
apply(Ys,2,var,na.rm=T)
plot(apply(Ys,2,var,na.rm=T))
sapply(list.files(path = 'G2F_byTrait_Gcors/',pattern = 'G',full.names=T),function(x) Image(readRDS(x)))
sapply(list.files(path = 'G2F_byTrait_Gcors/',pattern = 'G',full.names=T),function(x) print(Image(readRDS(x))))
sapply(list.files(path = 'G2F_byTrait_Gcors/',pattern = 'Gcor',full.names=T),function(x) print(Image(readRDS(x))))
list.files(path = 'G2F_byTrait_Gcors/',pattern = 'Gcor',full.names=T)
G = readRDS("G2F_byTrait_Gcors//Gcor_ASI_1.rds")
Y = fread('BLUP_matrices/ASI_BLUPs.csv',data.table=F)
Image(G)
hist(boxplot(G))
boxplot(G)
hist(G[,10])
hist(G[,11])
hist(G[,12])
hist(G[,13])
hist(G[,9])
hist(G[,8])
boxplot(G[,1:20])
hist(G[,7])
colnames(G)[7]
plot(G[,7])
colnames(Y)[1:10]
plot(Y[,c(8,2)])
plot(Y[,c(8,3)])
plot(Y[,c(8,4)])
plot(Y[,c(8,5)])
plot(Y[,c(8,6)])
hist(cor(Y[,-1],use='p')[,7])
colnames(cor(Y[,-1],use='p'))[7]
Image(cor(Y[,-1],use='p'))
Image(tcrossprod(Lambdas[[1]]))
Image(G)
Image(cor(Y[,-1],use='p'))
fields_metadata
fields_metadata[fields_metadata$SiteYear == 'INH1.2014',]
fields_2014[fields_2014$Experiment == 'INH1',]
head(results)
subset(results,SiteYear == 'INH1.2014')
subset(results,SiteYear == 'INH1.2014' & trait == 'ASI')
boxplot(subset(results,SiteYear == 'INH1.2014' & trait == 'ASI')[,-c(1:3)])
Y[,8]
var(Y[,8],na.rm=T)
sapply(list.files(path = 'G2F_byTrait_Gcors/',pattern = 'Gcor',full.names=T),function(x) print(Image(readRDS(x))))
sapply(list.files(path = 'BLUP_matrices',pattern = 'csv',full.names = T),function(x) Image(cor(fread(x,data.table=F)[,-1],use='p')))
sapply(list.files(path = 'BLUP_matrices',pattern = 'csv',full.names = T),function(x) print(Image(cor(fread(x,data.table=F)[,-1],use='p'))))
Ys=list.files(path = 'BLUP_matrices',pattern = 'csv',full.names = T),function(x) fread(x,data.table = F)
Ys=lapply(list.files(path = 'BLUP_matrices',pattern = 'csv',full.names = T),function(x) fread(x,data.table = F))
names(Ys)
list.files(path = 'BLUP_matrices',pattern = 'csv',full.names = T)
plot(Ys[,22],Ys[,50])
plot(Ys[[4]][,22],Ys[[4]][,50])
plot(Ys[[4]][,22],Ys[[4]][,60])
plot(Ys[[4]][,22],Ys[[4]][,70])
plot(Ys[[4]][,22],Ys[[4]][,80])
plot(Ys[[4]][,52],Ys[[4]][,80])
lapply(Ys,function(x) print(Image(cor(x[,-1],use='p'))))
A_mat = fread('Data/g2f_2014_zeaGBSv27_CenteredIBS_allYears.txt',data.table=F)
rownames(A_mat) = A_mat[,1]
A_mat = as.matrix(A_mat[,-1])
colnames(A_mat) = rownames(A_mat)
dim(A_mat)
Image(A_mat)
results_subset = results[,c('trait','i','SiteYear','BSFG_U','phenix_Y','means_U','rrBLUP')]
colnames(results_subset)[4:7] = c('MegaLMM','phenix','GBLUP(env BLUPs)','GBLUP(univariate)')
library(emmeans)
summ_results = foreach(trait. = traits,.combine = 'rbind') %do% {
results_trait = subset(results_subset,trait == trait.)
# results_trait_means = aggregate(cbind(BSFG_Eta,BSFG_U,rrBLUP,phenix_Y,phenix_U,means_U)~SiteYear+trait,results_trait,FUN=mean)
results_trait_means = aggregate(cbind(MegaLMM,phenix,`GBLUP(env BLUPs)`,`GBLUP(univariate)`)~SiteYear+trait,results_trait,FUN=mean)
results_trait_means_tall = pivot_longer(results_trait_means,cols = -c(1:2))
res = lm(value ~ SiteYear + name,results_trait_means_tall)
effects = summary(emmeans(res,spec = 'name'))
data.frame(Trait = trait.,as.data.frame(effects))
}
position = position_dodge()
summ_results$name = factor(summ_results$name,levels = unique(summ_results$name)[c(2,1,4,3)])
(p_accuracy <- ggplot(summ_results,aes(x=Trait,y=emmean)) +
geom_errorbar(aes(group = interaction(name,Trait),ymin = lower.CL,ymax = upper.CL),position=position_dodge(),size=.5) +
geom_bar(aes(group = interaction(name,Trait),fill = name),stat='identity',position = position_dodge()) +
scale_fill_discrete(name = 'Method') +
ylab('Estimated prediction accuracy')
)
results_subset = results[,c('trait','i','SiteYear','BSFG_Eta','phenix_Y','means_U','rrBLUP')]
colnames(results_subset)[4:7] = c('MegaLMM','phenix','GBLUP(env BLUPs)','GBLUP(univariate)')
library(emmeans)
summ_results = foreach(trait. = traits,.combine = 'rbind') %do% {
results_trait = subset(results_subset,trait == trait.)
# results_trait_means = aggregate(cbind(BSFG_Eta,BSFG_U,rrBLUP,phenix_Y,phenix_U,means_U)~SiteYear+trait,results_trait,FUN=mean)
results_trait_means = aggregate(cbind(MegaLMM,phenix,`GBLUP(env BLUPs)`,`GBLUP(univariate)`)~SiteYear+trait,results_trait,FUN=mean)
results_trait_means_tall = pivot_longer(results_trait_means,cols = -c(1:2))
res = lm(value ~ SiteYear + name,results_trait_means_tall)
effects = summary(emmeans(res,spec = 'name'))
data.frame(Trait = trait.,as.data.frame(effects))
}
position = position_dodge()
summ_results$name = factor(summ_results$name,levels = unique(summ_results$name)[c(2,1,4,3)])
(p_accuracy <- ggplot(summ_results,aes(x=Trait,y=emmean)) +
geom_errorbar(aes(group = interaction(name,Trait),ymin = lower.CL,ymax = upper.CL),position=position_dodge(),size=.5) +
geom_bar(aes(group = interaction(name,Trait),fill = name),stat='identity',position = position_dodge()) +
scale_fill_discrete(name = 'Method') +
ylab('Estimated prediction accuracy')
)
Gcors = lapply(trait_names,function(trait.) readRDS(sprintf('G2F_byTrait_Gcors/Gcor_%s_1.rds',trait.)))
names(Gcors) = traits
library(DescTools)
library(numform)
transform = function(x) FisherZ(x)
# transform = function(x) x
scales::trans_new('fisherz','FisherZ','FisherZInv')
results_sum=foreach(trait. = traits,.combine = 'rbind') %do% {
results$MvLMM_effect = unlist(results$BSFG_Eta - results$rrBLUP)
results$MvLMM_effect_vst = unlist(transform(results$BSFG_Eta) - transform(results$rrBLUP))
results_sum = aggregate(cbind(rrBLUP,BSFG_Eta,MvLMM_effect,MvLMM_effect_vst) ~ SiteYear,subset(results,trait == trait.),FUN = mean)
results_sum$MvLMM_effect_percent = results_sum$MvLMM_effect/results_sum$rrBLUP
results_sum$Year = sapply(results_sum$SiteYear,function(x) {a=strsplit(x,'.',fixed=T)[[1]];a[length(a)]})
Gcor = Gcors[[trait.]]
Gcor = Gcor[results_sum$SiteYear,results_sum$SiteYear]
diag(Gcor) = NA
results_sum$ave_Gcor = rowMeans(Gcor^2,na.rm=T)
# results_sum$max_Gcor = apply(Gcor^2,1,max,na.rm=T)
results_sum$max_Gcor = apply((Gcor),1,max,na.rm=T)
# results_sum$Gcor_90q = apply(Gcor^2,1,function(x) quantile(na.omit(x),.9))
# h2s = readRDS(sprintf('G2F_byTrait_Gcors/h2s_%s_1.rds',trait.))
# results_sum$h2 = h2s[results_sum$SiteYear]
data.frame(Trait = trait.,results_sum)
}
results_sum$Trait = factor(results_sum$Trait,levels = traits)
(p_regression = ggplot(results_sum,aes(x=max_Gcor,y=MvLMM_effect_vst)) +
geom_point() + geom_smooth(span=1.5) + facet_wrap(~Trait) + #coord_equal() +
# scale_x_continuous(trans = scales::trans_new('fisherz','FisherZ','FisherZInv'),breaks = scales::extended_breaks(n=10),minor_breaks = NULL,labels = function(x) sprintf('%.1f',x)) +
scale_x_continuous(limits=c(0.05,.95),trans = scales::trans_new('fisherz','FisherZ','FisherZInv'),breaks = scales::extended_breaks(n=10),minor_breaks = NULL,labels = function(x) f_num(x,digits=1)) +
xlab('maximum genetic correlation') + #with other site:year
ylab('Benefit of MvLMM'))  # (difference of z-transformed correlations)
# (p_regression = ggplot(results_sum,aes(x=ave_Gcor,y=MvLMM_effect_vst)) + geom_smooth(span=1.5) + geom_point() + facet_wrap(~Trait) + scale_x_continuous(trans=scales::trans_new('FisherZ',FisherZ,FisherZInv)))
Lambdas[[1]]
Image(Lambdas[[1]])
plot(Lambdas[[1]][,1],type='l')
rownames(Lambdas)
rownames(Lambdas[[1]])
fields_metadata = fread('Data/fields_locations_allYears.csv',data.table=F)
Lambdas = lapply(list.files(path= 'G2F_byTrait_Gcors/',pattern = 'Lamb',full.names = T),readRDS)
head(fields_metadata)
fields_metadata$SiteYear
fields_metadata$Year = sapply(fields_metadata$SiteYear,function(x) {a = strsplit(x,'-')[[1]];a[length(a)]})
fields_metadata$Year
fields_metadata = fread('Data/fields_locations_allYears.csv',data.table=F)
fields_metadata$SiteYear = sub('-','.',sub('-','.',fields_metadata$SiteYear))
fields_metadata$SiteYear
fields_metadata$Year = sapply(fields_metadata$SiteYear,function(x) {a = strsplit(x,'.',fixed=T)[[1]];a[length(a)]})
fields_metadata$Year
fields_metadata$Year = factor(sapply(fields_metadata$SiteYear,function(x) {a = strsplit(x,'.',fixed=T)[[1]];a[length(a)]}))
Lambda = Lambdas[[1]]
m = lm(Lambda[,i]~Year+poly(lat,3)+poly(long,3),fields_metadata[match(rownames(Lambda),fields_metadata$SiteYear)])
m = lm(Lambda[,i]~Year+poly(lat,3)+poly(long,3),fields_metadata[match(rownames(Lambda),fields_metadata$SiteYear),])
i=1
m = lm(Lambda[,i]~Year+poly(lat,3)+poly(long,3),fields_metadata[match(rownames(Lambda),fields_metadata$SiteYear),])
m
anova(m)
regs = foreach(Lambda = Lambdas,.combine = c) %do% {
foreach(i =1:30,.combine = c) %do% {
m = lm(Lambda[,i]~Year+poly(lat,3)+poly(long,3),fields_metadata[match(rownames(Lambda),fields_metadata$SiteYear),])
}
}
lapply(regs,function(x) anova(m)$Pr)
regs[[1]]
anova(regs[[1]])
regs = foreach(Lambda = Lambdas) %do% {
foreach(i =1:30) %do% {
m = lm(Lambda[,i]~Year+poly(lat,3)+poly(long,3),fields_metadata[match(rownames(Lambda),fields_metadata$SiteYear),])
m
}
}
anova(regs[[1]])
regs[[1]]
length(regs)
regs = foreach(Lambda = Lambdas,.combine = c) %do% {
foreach(i =1:30) %do% {
m = lm(Lambda[,i]~Year+poly(lat,3)+poly(long,3),fields_metadata[match(rownames(Lambda),fields_metadata$SiteYear),])
m
}
}
length(regs)
regs[[1]]
anova(regs[[1]])
regs = foreach(trt=names(Lambdas),.combine = rbind) %do% {
Lambda = Lambdas[[trt]]
foreach(i =1:30,.combine = rbind) %do% {
m = lm(Lambda[,i]~Year+poly(lat,3)+poly(long,3),fields_metadata[match(rownames(Lambda),fields_metadata$SiteYear),])
data.frame()
}
}
regs = foreach(trt=names(Lambdas),.combine = rbind) %do% {
Lambda = Lambdas[[trt]]
foreach(i =1:30,.combine = rbind) %do% {
m = lm(Lambda[,i]~Year+poly(lat,3)+poly(long,3),fields_metadata[match(rownames(Lambda),fields_metadata$SiteYear),])
data.frame(trt = trt,i=i,anova(m)$Pr)
}
}
regs
names(Lambdas)
list.files(path= 'G2F_byTrait_Gcors/',pattern = 'Lamb',full.names = T)
Lambdas = lapply(list.files(path= 'G2F_byTrait_Gcors/',pattern = 'Lamb',full.names = T),readRDS)
names(Lambdas) = c('ASI','Grain Yield','Plant Height','DTS')
fields_metadata = fread('Data/fields_locations_allYears.csv',data.table=F)
fields_metadata$SiteYear = sub('-','.',sub('-','.',fields_metadata$SiteYear))
fields_metadata$Year = factor(sapply(fields_metadata$SiteYear,function(x) {a = strsplit(x,'.',fixed=T)[[1]];a[length(a)]}))
regs = foreach(trt=names(Lambdas),.combine = rbind) %do% {
Lambda = Lambdas[[trt]]
foreach(i =1:30,.combine = rbind) %do% {
m = lm(Lambda[,i]~Year+poly(lat,3)+poly(long,3),fields_metadata[match(rownames(Lambda),fields_metadata$SiteYear),])
data.frame(trt = trt,i=i,anova(m)$Pr)
}
}
regs
anova(m)
anova(m)$Pr
data.frame(trt = trt,i=i,t(anova(m)$Pr[1:3]))
colnames(d)[3:5]
d = data.frame(trt = trt,i=i,t(anova(m)$Pr[1:3]))
colnames(d)[3:5]
m = lm(Lambda[,i]~Year+poly(lat,2)+poly(long,2),fields_metadata[match(rownames(Lambda),fields_metadata$SiteYear),])
d = data.frame(trt = trt,i=i,t(anova(m)$Pr[1:3]))
colnames(d)[3:5] = c('Year','Lat','Long')
d
regs = foreach(trt=names(Lambdas),.combine = rbind) %do% {
Lambda = Lambdas[[trt]]
foreach(i =1:30,.combine = rbind) %do% {
m = lm(Lambda[,i]~Year+poly(lat,2)+poly(long,2),fields_metadata[match(rownames(Lambda),fields_metadata$SiteYear),])
d = data.frame(trt = trt,i=i,t(anova(m)$Pr[1:3]))
colnames(d)[3:5] = c('Year','Lat','Long')
d
}
}
regs
ggplot(regs,aes(x=i,y=-log10(Year))) + geom_line(aes(color = trt))
ggplot(regs,aes(x=i,y=-log10(Lat))) + geom_line(aes(color = trt))
trt = 'Grain Yield'
i=4
Lambda = Lambdas[[trt]]
m = lm(Lambda[,i]~Year+poly(lat,2)+poly(long,2),fields_metadata[match(rownames(Lambda),fields_metadata$SiteYear),])
d = data.frame(trt = trt,i=i,t(anova(m)$Pr[1:3]))
colnames(d)[3:5] = c('Year','Lat','Long')
d
plot(Lambda[,i]~fields_metadata[match(rownames(Lambda),fields_metadata$SiteYear),]$lat)
ggplot(regs,aes(x=i,y=-log10(Long))) + geom_line(aes(color = trt))
ggplot(regs,aes(x=i,y=-log10(Lat))) + geom_line(aes(color = trt))
trt ='DTS'
Lambda = Lambdas[[trt]]
i
m = lm(Lambda[,i]~Year+poly(lat,2)+poly(long,2),fields_metadata[match(rownames(Lambda),fields_metadata$SiteYear),])
d = data.frame(trt = trt,i=i,t(anova(m)$Pr[1:3]))
colnames(d)[3:5] = c('Year','Lat','Long')
d
anova(d)
anova(m)
summary(m)
Image(tcrossprod(Lambda))
Image(Lambda)
summary(m)
Image(tcrossprod(Lambda[,-1]))
Image(tcrossprod(Lambda[,-c(1:2)]))
Image(tcrossprod(Lambda[,-c(1:3)]))
Image(tcrossprod(Lambda[,-c(1:4)]))
log2(5/1)
2^5
